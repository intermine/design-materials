<?xml version="1.0"?>

<article>

<artheader>
<date>2002-7-1</date>
<title>ISMB 2003</title>
<authorgroup>
<author>
<firstname>Andrew</firstname>
<surname>Varley</surname>
</author>
<author>
<firstname>Richard</firstname>
<surname>Smith</surname>
</author>
</authorgroup>
</artheader>


<graphic fileref="andy_richard" width="70%" align="center"/>

<sect1>

<title>BOSC</title>

<sect2>
<title>BioJava</title>
<para>
BioJava use "bit packing" of large sequences in memory.
</para>
<para>
Have a comprehensice GUI library now. We think this is heavily sequence-orientated, but that is just a guess.
</para>
<para>
OBDA (Open Bio Database Access). Everyone was talking about this as a
common (ie. between the bio* languages) way of talking to datasources
such as RDBMS, flat-file, DAS, registry, etc. It is supposed to make
it transparent as to which source you are getting data
from. Configured by a config file.
</para>
<para>
</para>


</sect2>

<sect2>
<title>BioPerl-db</title>
<para>
An O/R mapping from bioperl objects to BioSQL (+Chado etc??)
schema. Provides persistence. The mapping was defined for each
persistence-capable object in a separate .pm file (one for each
object/database combination (ie. quite manual). Planning to add
lazy-loading but haven't yet.
</para>
<para>
Has a query interface. Queries were defined in object space. Results
were collection of one type of object, but queries could place
constraints on child objects. Looked messy, but that might have been
because Perl is messy, not this in particular!!
</para>

</sect2>

<sect2>
<title>BioSQL</title>

<para>Datastore for Bio* projects. Covers genes, sequences, etc. All
Bio* have inputs and outputs to BioSQL.
</para>

</sect2>
<sect2>
<title>KEGG/KEGG API</title>

<para>
KEGG is a large database covering loads of enzyme/pathway
information. There is a SOAP/webservice interface which might be worth
looking at. There are a series of pre-canned queries that you can pass
parameters to.
</para> 

</sect2>
<sect2>
<title>BioGopher</title>
<ulink url="http://www.ncicb.nci.nih.gov"/>

<para>
Tool for doing queries across caBIO databases, where each database has
the same schema but contains different data. Runs off a metadata file
and then lets you view an object with an expandable view of its fields
(recursive). Lets you set constraints on these fields and then run a
query. Uses quite nice frame system. We may be able to make use of
this, or parts of this. Anonymous CVS access is not available, but I
think that source code can be downloaded.
</para>

<para>
Also for integrating spreadsheets with the caBIO system. Basically, if
you choose a column of a spreadsheet, you can use this as the input a
caBIO query and inserts the query results back into the
spreadsheet.</para>

</sect2>
<sect2>
<title>KEGG API</title>
<para>
KEGG is a large database covering loads of enzyme/pathway
information. There is a SOAP/webservice interface which might be worth
looking at. There are a series of pre-canned queries that you can pass
parameters to.
</para> 

</sect2>

<sect2>

<title>Webservices</title>
<ulink url="http://www.webservices.org"/>

<para>
Martin Senger gave an interesting overview of webservices (he
mentioned us, because we mentioned webservices!!). Investigate
differences between XML-RPC and SOAP and WSDL.
</para>

</sect2>

<sect2>

<title>GMOD</title>
<ulink url="http://gmod.sourceforge.net"/>
<para>
No new info, just a summary of the selection of tools available under
the GMOD umbrella. Plugged Chado, of course!!
</para>

</sect2>

<sect2>

<title>Debian bioinformatics packaging effort</title>
<ulink url="http://debian.bioinformatics.unsw.edu.au"/>
<para>
Wants volunteers to package bioinformatics utilities for Debian.
</para> 

</sect2>

</sect1>

<sect1>
<title>ISMB</title>

<para>Overriding take-home message: everybody is doing integration of
one sort or another!  [Anyone who isn't doing yet is interested in it]</para>

<sect2>
<title>caBIO</title>

<para>
Met Joshua Phillips, a developer on the project, who says that FlyMine
and caBIO are very similar. caBIO is basically a selection of cancer
database under a common schema. They do automatic generation of the
schema etc from a UML file. Their database layer is not as good, for
example they do not do paging. They were very interested in using the
query optimiser module, and have downloaded it, so we'll probably be
hearing from them soon. Were interested in writing an Oracle EXPLAIN
parser, which they would contribute back to FlyMine.  Also interested
in running queries across databases/integrating databases.  Showed an
interest in a graphical query building system and suggested collaboration
on requirements for such a system.
</para>

</sect2>

<sect2>
<title>myGrid</title>
<ulink url="http://www.mygrid.org.uk"/>
<ulink url="mygrid">[poster]</ulink>

<para>
myGrid has some sort of distributed query processor. This was not
elaborated on in the talk, but it would be worth an investigate of the
code. The myGrid paper in the conference proceedings is worth a read.
</para>
</sect2>

<sect2>
<title>Talisman</title>
<ulink url="http://www.mygrid.org.uk"/>

<para>
Talisman is part of the myGrid project and is a (one file?) method of
building quite complex web interfaces. It was used in the SwissProt
project for building web pages for the internal curators to use. The
speaker (Tom Oinn) said "...it is probably not suitable for building
your public web pages". If we end up doing internal (eg. curation) web
pages it might come in useful. There is a paper in the conference
proceedings covering this project.
</para>

</sect2>

<sect2>
<title>Get3D/CAS</title>
<ulink url="CAS">[poster]</ulink>
<ulink url="Get3D">[poster]</ulink>

<para>
This is a project from the Victorian Bioinformatics Consortium. They
wouldn't tell us the web address or give any more information as
"...we want to get it published first"!! Bit bizarre.
</para>

<para>
The Get3D part is a 3D object viewer. Each set of objects is
represented by a sphere, relationships between objects by a line
linking spheres. You can put constraints on the objects by clicking on
a sphere and filling in the pop-up box. The number of objects that
fulfil the constraints is given on the links. It looked quite a nice
interface. I don't think that the queries got any more complicated
than that.
</para>

<para>
The CAS part involves integrating data by a catogory based method. See
poster for full details.
</para>

</sect2>

<sect2>
<title>MineLink (IBM)</title>

<para>

This is a bolt-on on top of DiscoveryLink that enables you to write
workflows (load from this source, do this processing, output to here,
etc. etc.).
</para>

</sect2>

<sect2>
<title>DiscoveryHub (GeneticXchange)</title>

<para>
Again, this is a workflow system that looks quite good. We went to
(half of) a software demo and Richard talked to them at length.  [R] The
core of their system is the Kleisli query engine (see paper by Wong)
who's creator started the company.  Although details of Kleisli seem
to be available it is not free software, is being commercialised by
GeneticXchange.  Data is not pulled into one database, queries get
sent to the actaull data sources whether local or on internet
(i.e. a federated data warehouse approach).  Kleisli/their system 
seems to have something to do with storing un-flattened object trees
that I didn't really follow/wasn't well explained.
</para>

</sect2>

<sect2>
<title>Knowledge Discovery Tool (Accenture)</title>
<ulink url="hidden_linkages">[poster]</ulink>


<para>
[A] Interesting looking commercial project. Loads data from different
sources into a single (fairly simple) schema (gene, protein,
literature reference, etc.). Has an applet viewer that basically has a
set of nine windows that represent a type of object, and then has loads
of lines representing links between the objects. Don't think the
queries were particularly complicated in themselves, but you could
specify how far removed from one object you wanted to allow when
showing links. Said it takes 4 weeks to load data into an empty
database, but was doing incremental updates after that.
</para>
<para>
[R] Again doesn't actually pull data into a single database but I think it
could.  Current implementation just integrates indexes/pointers to 
remote sources - i.e. integration scheme is held locally, queries are
run over net.  Still appears to be fully integrated and seems to run fast.
Huge amount of source data.  Integration is done by a curator who works 
through a GUI to solve conflicts.  Once a conflict/match is solved it is
stored in a thesaurus for re-use.
</para>

<para>
[A] Did set me wondering whether we should kick-start FlyMine with a
simple schema such as this to just get going, ie. not bother about all
the sequence stuff, just have 8 or 10 main objects that span 4 or 5
external databases.
</para>

</sect2>

<sect2>
<title>Japanese data warehouse project</title>
<ulink url="data_warehouse.sxi">[poster]</ulink>

<para>
Does query rewriting (in Perl) to use automatically use aggregate
tables (in his case, calculating standard deviations).  Doesn't actually
parse an SQL string, query 'rewriting' is done in application before
object representation is converted to SQL.
</para>
</sect2>

<sect2>
<title>Integrated modelling of proteins</title>
<ulink url="integrated_protein">[poster]</ulink>
</sect2>

<sect2>
<title>Natural language processing</title>

<para>
There was a talk on natural language processing of queries, converting
them into SQL, by reference to a thesaurus. Quite interesting,
especially if it could be done in object space. Full paper is in the
conference proceedings.</para>

<para>Poster was not attended by the presentees, for some reason, so
did not get to speak to them.</para>

</sect2>
<sect2>
<title>UML/XML-schema</title>
<ulink url="xml_uml">[poster]</ulink>

<para>
Amusing maths guy from University of Arkansas has written a paper on 
representing XML schemas in UML.  He hasn't written a tool to generate
schamas from the UML diagrams and couldn't remember where he had published
his paper.
</para>

</sect2>
</sect1>

<sect1>
<title>Who was interested in FlyMine and in what context?</title>

<itemizedlist>
<listitem>Josh Phillips from caBIO, keen to use query optimiser and
interested in looking at our code/sharing ideas.  Also keen
to collaborate/contribute/use a graphical wuery interface.</listitem>

<listitem>Three (or more) people considering using it as a data
storing/warehousing system for  a single data source (i.e.
don't have a need to integrate data).  Reason for interest
seemed to be the simple creation from UML.  One of these was
Mike Weng (??), ex-Incyte who would use it with an EJB-based
LIMS.</listitem>

<listitem>A lady from UCL who runs a [bio]informatics group, users
researching Anopheles want an easy way to find comparable
Drosophila genes.</listitem>

<listitem>A funny japanese man says Proteomics data is unreliable.</listitem>

<listitem>A lady from the Finland Super-computer centre is looking
from ways to intergrate databases, may download and look.</listitem>

</itemizedlist>

</sect1>

<sect1>

<title>Thoughts on FlyMine that we had during ISMB</title>

<para>We are probably going to need some kind of manual curation when
joining data sets. However (whoever?) this is done, we need to make
records of the compromises made (which we would re-use) and then how 
about making those "manual merge" files available on the website for 
others to use when building their own data sets. Would need to think 
a bit more about how we would do this in practice.</para>

<para>Given the amount of time and effort other groups have been
devoting to database integration we (I) may have underestimated the
amount of work involved.  It seems best to build a tool to facilitate
curated integration (conflict resolution) rather than trying to do
this all programatically.  In the interest of making FlyMine as
modular as possible this could be another stand alone piece of
software. If the integrated data could be output (e.g. in XML) the
integration tool could be used to feed database applications other
than a FlyMine ObjectStore.</para>

<para>This led to idea led to discussion on implementing an ObjectStore
that talks to Hypersonic SQL (an in-memory RDBMS) which we may
be able to use in various tools.</para>

<para>Simpler data model, as well as, or instead of, or initially, to
get things going.</para>


</sect1>
</article>
